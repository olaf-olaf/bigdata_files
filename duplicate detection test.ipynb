{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import glob\n",
    "import hashlib \n",
    "from PIL import Image, ImageCms\n",
    "import numpy as np\n",
    "from blockhash import blockhash\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from siftdwthash import sift_dwt_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_folders = ['boxblurred', 'gaussianblurred', 'medianblurred', 'modeblurred']\n",
    "noise_folders = ['gaussiannoise', 'peppernoise', 'poissonnoise', 'saltnoise', 'specklenoise', 'diffformat']\n",
    "geo_folders = ['cropped', 'rotated', 'scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_originals():\n",
    "    images = []\n",
    "    for filename in glob.glob('images/original/*'):\n",
    "        img = Image.open(filename)\n",
    "        images.append(img)\n",
    "    return images\n",
    "images  = get_images_originals()\n",
    "\n",
    "def shuffle_sort(a):\n",
    "\td = defaultdict(list)    \n",
    "\tfor thing in a:\n",
    "\t\tif (len(thing) < 1):\n",
    "\t\t\tcontinue\n",
    "\t\td[thing[0]] += thing,\n",
    "\treturn dict(sorted(d.items())).values()\n",
    "def reduce_aggr(xs):\n",
    "\tsum = 0\n",
    "\tfor x in xs:\n",
    "\t\tsum += x[1]\n",
    "\treturn [xs[0][0], sum]\n",
    "def map_sift_dwt_hash():\n",
    "    files = []\n",
    "    counter = 0\n",
    "    for filename in glob.glob('images/original/*'):\n",
    "        files.append([sift_dwt_hash(filename), 1])\n",
    "        counter += 1\n",
    "    return files\n",
    "\n",
    "# def map_md5_hash():\n",
    "#     files = []\n",
    "#     for filename in glob.glob('images/original/*'):\n",
    "#         f = open(filename, 'rb')\n",
    "#         jpgdata = f.read()\n",
    "#         f.close() \n",
    "#         files.append([hashlib.md5(jpgdata).hexdigest(), 1])\n",
    "#     return files\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get blur results\n",
    "def map_md5_hash(folder):\n",
    "    files = []\n",
    "    for filename in glob.glob('images/original/*'):\n",
    "        f = open(filename, 'rb')\n",
    "        jpgdata = f.read()\n",
    "        f.close() \n",
    "        files.append([hashlib.md5(jpgdata).hexdigest(), 1])\n",
    "    for filename in glob.glob('images/'+folder+'/*'):\n",
    "        f = open(filename, 'rb')\n",
    "        jpgdata = f.read()\n",
    "        f.close() \n",
    "        files.append([hashlib.md5(jpgdata).hexdigest(), 1])\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxblurred\n",
      "CHECKING MD5 boxblurred\n",
      "CHECKING BLOCK boxblurred\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 38.972809667673715\n",
      "gaussianblurred\n",
      "CHECKING MD5 gaussianblurred\n",
      "CHECKING BLOCK gaussianblurred\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 27.492447129909365\n",
      "medianblurred\n",
      "CHECKING MD5 medianblurred\n",
      "CHECKING BLOCK medianblurred\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 36.25377643504532\n",
      "modeblurred\n",
      "CHECKING MD5 modeblurred\n",
      "CHECKING BLOCK modeblurred\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 18.12688821752266\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boxblurred</th>\n",
       "      <th>gaussianblurred</th>\n",
       "      <th>medianblurred</th>\n",
       "      <th>modeblurred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.97281</td>\n",
       "      <td>27.492447</td>\n",
       "      <td>36.253776</td>\n",
       "      <td>18.126888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   boxblurred  gaussianblurred  medianblurred  modeblurred\n",
       "0     0.00000         0.000000       0.000000     0.000000\n",
       "1    38.97281        27.492447      36.253776    18.126888"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test md5 hash\n",
    "def map_md5_hash(folder):\n",
    "    print(\"CHECKING MD5\", folder)\n",
    "    files = []\n",
    "    for filename in glob.glob('images/original/*'):\n",
    "        f = open(filename, 'rb')\n",
    "        jpgdata = f.read()\n",
    "        f.close() \n",
    "        files.append([hashlib.md5(jpgdata).hexdigest(), 1])\n",
    "    for filename in glob.glob('images/'+folder+'/*'):\n",
    "        f = open(filename, 'rb')\n",
    "        jpgdata = f.read()\n",
    "        f.close() \n",
    "        files.append([hashlib.md5(jpgdata).hexdigest(), 1])\n",
    "    return files\n",
    "def map_block_hash(folder):\n",
    "    print(\"CHECKING BLOCK\", folder)\n",
    "    files = []\n",
    "    for filename in glob.glob('images/original/*'):\n",
    "        img = Image.open(filename)\n",
    "        img = img.resize((256,256))\n",
    "        files.append([blockhash(img,16), 1])\n",
    "    for filename in glob.glob('images/'+folder+'/*'):\n",
    "        img = Image.open(filename)\n",
    "        img = img.resize((256,256))\n",
    "        files.append([blockhash(img,16), 1])    \n",
    "    return files\n",
    "\n",
    "results = []\n",
    "md_5_results = []\n",
    "block_results = []\n",
    "for folder in blur_folders:\n",
    "    print(folder)\n",
    "    map_result_md5 = map_md5_hash(folder)\n",
    "    shuffle_sort_result_md5 = shuffle_sort(map_result_md5)\n",
    "    reduce_result_md5 = [reduce_aggr(x) for x in shuffle_sort_result_md5]\n",
    "    \n",
    "    map_result_block = map_block_hash(folder)\n",
    "    shuffle_sort_result_block = shuffle_sort(map_result_block)\n",
    "    reduce_result_block = [reduce_aggr(x) for x in shuffle_sort_result_block]\n",
    "    \n",
    "    \n",
    "    undetected_dups_md5 = len(reduce_result_md5) - 331\n",
    "    print(\"UNDETECTED MD%\")\n",
    "    percentage_detected_md5 = (331 - undetected_dups_md5)\n",
    "    print(\"md5\",(percentage_detected_md5 / 331) * 100)\n",
    "    md_5_results.append((percentage_detected_md5 / 331) * 100)\n",
    "    \n",
    "    undetected_dups_block = len(reduce_result_block) - 331\n",
    "    percentage_detected_block = (331 - undetected_dups_block)\n",
    "    print(\"block\",(percentage_detected_block / 331) * 100)\n",
    "    block_results.append((percentage_detected_block / 331) * 100)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "results.append(md_5_results)\n",
    "results.append(block_results)\n",
    "    \n",
    "df = pd.DataFrame(results, columns = blur_folders)\n",
    "df.to_csv('blur.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussiannoise\n",
      "CHECKING MD5 gaussiannoise\n",
      "CHECKING BLOCK gaussiannoise\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 12.386706948640484\n",
      "peppernoise\n",
      "CHECKING MD5 peppernoise\n",
      "CHECKING BLOCK peppernoise\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 10.876132930513595\n",
      "poissonnoise\n",
      "CHECKING MD5 poissonnoise\n",
      "CHECKING BLOCK poissonnoise\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 44.71299093655589\n",
      "saltnoise\n",
      "CHECKING MD5 saltnoise\n",
      "CHECKING BLOCK saltnoise\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 10.876132930513595\n",
      "specklenoise\n",
      "CHECKING MD5 specklenoise\n",
      "CHECKING BLOCK specklenoise\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 37.764350453172206\n",
      "diffformat\n",
      "CHECKING MD5 diffformat\n",
      "CHECKING BLOCK diffformat\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 100.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gaussiannoise</th>\n",
       "      <th>peppernoise</th>\n",
       "      <th>poissonnoise</th>\n",
       "      <th>saltnoise</th>\n",
       "      <th>specklenoise</th>\n",
       "      <th>diffformat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.386707</td>\n",
       "      <td>10.876133</td>\n",
       "      <td>44.712991</td>\n",
       "      <td>10.876133</td>\n",
       "      <td>37.76435</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gaussiannoise  peppernoise  poissonnoise  saltnoise  specklenoise  \\\n",
       "0       0.000000     0.000000      0.000000   0.000000       0.00000   \n",
       "1      12.386707    10.876133     44.712991  10.876133      37.76435   \n",
       "\n",
       "   diffformat  \n",
       "0         0.0  \n",
       "1       100.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "md_5_results = []\n",
    "block_results = []\n",
    "for folder in noise_folders:\n",
    "    print(folder)\n",
    "    map_result_md5 = map_md5_hash(folder)\n",
    "    shuffle_sort_result_md5 = shuffle_sort(map_result_md5)\n",
    "    reduce_result_md5 = [reduce_aggr(x) for x in shuffle_sort_result_md5]\n",
    "    \n",
    "    map_result_block = map_block_hash(folder)\n",
    "    shuffle_sort_result_block = shuffle_sort(map_result_block)\n",
    "    reduce_result_block = [reduce_aggr(x) for x in shuffle_sort_result_block]\n",
    "    \n",
    "    \n",
    "    undetected_dups_md5 = len(reduce_result_md5) - 331\n",
    "    print(\"UNDETECTED MD%\")\n",
    "    percentage_detected_md5 = (331 - undetected_dups_md5)\n",
    "    print(\"md5\",(percentage_detected_md5 / 331) * 100)\n",
    "    md_5_results.append((percentage_detected_md5 / 331) * 100)\n",
    "    \n",
    "    undetected_dups_block = len(reduce_result_block) - 331\n",
    "    percentage_detected_block = (331 - undetected_dups_block)\n",
    "    print(\"block\",(percentage_detected_block / 331) * 100)\n",
    "    block_results.append((percentage_detected_block / 331) * 100)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "results.append(md_5_results)\n",
    "results.append(block_results)\n",
    "    \n",
    "df = pd.DataFrame(results, columns = noise_folders)\n",
    "df.to_csv('noise.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped\n",
      "CHECKING MD5 cropped\n",
      "CHECKING BLOCK cropped\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 0.0\n",
      "rotated\n",
      "CHECKING MD5 rotated\n",
      "CHECKING BLOCK rotated\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 1.5105740181268883\n",
      "scaled\n",
      "CHECKING MD5 scaled\n",
      "CHECKING BLOCK scaled\n",
      "UNDETECTED MD%\n",
      "md5 0.0\n",
      "block 28.3987915407855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cropped</th>\n",
       "      <th>rotated</th>\n",
       "      <th>scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.510574</td>\n",
       "      <td>28.398792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cropped   rotated     scaled\n",
       "0      0.0  0.000000   0.000000\n",
       "1      0.0  1.510574  28.398792"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "md_5_results = []\n",
    "block_results = []\n",
    "for folder in geo_folders:\n",
    "    print(folder)\n",
    "    map_result_md5 = map_md5_hash(folder)\n",
    "    shuffle_sort_result_md5 = shuffle_sort(map_result_md5)\n",
    "    reduce_result_md5 = [reduce_aggr(x) for x in shuffle_sort_result_md5]\n",
    "    \n",
    "    map_result_block = map_block_hash(folder)\n",
    "    shuffle_sort_result_block = shuffle_sort(map_result_block)\n",
    "    reduce_result_block = [reduce_aggr(x) for x in shuffle_sort_result_block]\n",
    "    \n",
    "    \n",
    "    undetected_dups_md5 = len(reduce_result_md5) - 331\n",
    "    print(\"UNDETECTED MD%\")\n",
    "    percentage_detected_md5 = (331 - undetected_dups_md5)\n",
    "    print(\"md5\",(percentage_detected_md5 / 331) * 100)\n",
    "    md_5_results.append((percentage_detected_md5 / 331) * 100)\n",
    "    \n",
    "    undetected_dups_block = len(reduce_result_block) - 331\n",
    "    percentage_detected_block = (331 - undetected_dups_block)\n",
    "    print(\"block\",(percentage_detected_block / 331) * 100)\n",
    "    block_results.append((percentage_detected_block / 331) * 100)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "results.append(md_5_results)\n",
    "results.append(block_results)\n",
    "    \n",
    "df = pd.DataFrame(results, columns = geo_folders)\n",
    "df.to_csv('geo.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test block hash\n",
    "# def map_md5_hash(folder):\n",
    "#     files = []\n",
    "#     for filename in glob.glob('images/original/*'):\n",
    "#         f = open(filename, 'rb')\n",
    "#         jpgdata = f.read()\n",
    "#         f.close() \n",
    "#         files.append([hashlib.md5(jpgdata).hexdigest(), 1])\n",
    "#     for filename in glob.glob('images/'+folder+'/*'):\n",
    "#         f = open(filename, 'rb')\n",
    "#         jpgdata = f.read()\n",
    "#         f.close() \n",
    "#         files.append([hashlib.md5(jpgdata).hexdigest(), 1])\n",
    "#     return files\n",
    "# def map_block_hash(folder):\n",
    "#     files = []\n",
    "#     for filename in glob.glob('images/original/*'):\n",
    "# #         print(\"ORIGINAL\", filename)\n",
    "\n",
    "#         img = Image.open(filename)\n",
    "#         img = img.resize((256,256))\n",
    "#         files.append([blockhash(img,16), 1])\n",
    "#     for filename in glob.glob('images/'+folder+'/*'):\n",
    "# #         print(filename)\n",
    "#         img = Image.open(filename)\n",
    "#         img = img.resize((256,256))\n",
    "#         files.append([blockhash(img,16), 1])    \n",
    "#     return files\n",
    "# results = []\n",
    "# for folder in folders:\n",
    "#     print(folder)\n",
    "#     map_result = map_block_hash(folder)\n",
    "#     shuffle_sort_result = shuffle_sort(map_result)\n",
    "#     reduce_result = [reduce_aggr(x) for x in shuffle_sort_result]\n",
    "#     undetected_dups = len(reduce_result) - 339\n",
    "#     percentage_detected = (339 - undetected_dups)\n",
    "#     print((percentage_detected / 339) * 100)\n",
    "#     results.append((percentage_detected / 339) * 100)\n",
    "# df = pd.DataFrame([results], columns = folders)\n",
    "# df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"block_hash.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
